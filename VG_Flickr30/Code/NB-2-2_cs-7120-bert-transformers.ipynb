{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-25T21:20:56.061701Z",
     "iopub.status.busy": "2023-04-25T21:20:56.061289Z",
     "iopub.status.idle": "2023-04-25T21:21:49.541621Z",
     "shell.execute_reply": "2023-04-25T21:21:49.540091Z",
     "shell.execute_reply.started": "2023-04-25T21:20:56.061663Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imagesize in /opt/conda/lib/python3.7/site-packages (1.4.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "465ad11a608a47239df7cb5f653e738b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da01d158a9cc4c21ab07f3dc65b88288",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4fecc219d5347e89b1f3bdd039f748d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cdf2338f876444f985b311b1b1a4a20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local Function Called......\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f18b73348b414a648da3e75d2dab6e2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local Function Called......\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09c3cd73592744d3bc08e0827883140c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local Function Called......\n"
     ]
    }
   ],
   "source": [
    "######################################################################################################################\n",
    "#                               Import Python Files for Sentence & Annotations Extraction                            #\n",
    "#                                        Provided as a Simple API on Github                                          #\n",
    "#                                https://github.com/BryanPlummer/flickr30k_entities                                  #\n",
    "######################################################################################################################\n",
    "\n",
    "# Uncomment the below line once in order for the code to run smoothly\n",
    "!pip install imagesize\n",
    "import os\n",
    "os.chdir(r\"/kaggle/input/vgrutils/Visual Grounding RefEx/Flickr30/\")\n",
    "import Utils.flickr30k_entities_utils\n",
    "from Utils.flickr30k_entities_utils import get_sentence_data, get_annotations\n",
    "import Utils.helper_functions\n",
    "from Utils.helper_functions import *\n",
    "import random \n",
    "import seaborn as sb\n",
    "import pickle\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "######################################################################################################################\n",
    "#                                                                                                                    #\n",
    "#                                                   Mapping Function                                                 #\n",
    "#                                                                                                                    #\n",
    "######################################################################################################################\n",
    "\"\"\"\n",
    "Mapping Function does the following,\n",
    "    - takes list of Image names as i/p and fetch Sentences & Annotations (contains bounding boxes)of all those Images\n",
    "    - passes those Sentences & Annotations to the func Phrase_Id_to_Bbox & gets Bounding Boxes for all phrases\n",
    "    in every image.\n",
    "    - also, passes those Sentences & Annotations to the func Phrase_Id_to_Phrases & extracts phrases contained in all\n",
    "    images.\n",
    "    \n",
    "    A typical look of the outputs would be:\n",
    "    \n",
    "        _Image_Train_Phrase_Id_to_Bbox -----> {'image_id_1' : {'Phrase_id_1' : [Bbox1, Bbox2 ... Bboxn],\n",
    "                                                              'Phrase_id_2' : [Bbox1, Bbox2 ... Bboxn],\n",
    "                                                              'Phrase_id_3' : [Bbox1, Bbox2 ... Bboxn],\n",
    "                                                              .\n",
    "                                                              .\n",
    "                                                              .\n",
    "                                                              'Phrase_id_n' : [Bbox1, Bbox2 ... Bboxn]}\n",
    "                                                              \n",
    "                                                'image_id_2' : {'Phrase_id_1' : [Bbox1, Bbox2 ... Bboxn],\n",
    "                                                              'Phrase_id_2' : [Bbox1, Bbox2 ... Bboxn],\n",
    "                                                              'Phrase_id_3' : [Bbox1, Bbox2 ... Bboxn],\n",
    "                                                              .\n",
    "                                                              .\n",
    "                                                              .\n",
    "                                                              'Phrase_id_n' : [Bbox1, Bbox2 ... Bboxn]}\n",
    "                                                              \n",
    "                                                              \n",
    "                                                              \n",
    "                                                              .\n",
    "                                                              .\n",
    "                                                              .\n",
    "                                                              .\n",
    "                                                              .\n",
    "                                                              .\n",
    "                                                              \n",
    "                                                              \n",
    "                                                'image_id_n' : {'Phrase_id_1' : [Bbox1, Bbox2 ... Bboxn],\n",
    "                                                              'Phrase_id_2' : [Bbox1, Bbox2 ... Bboxn],\n",
    "                                                              'Phrase_id_3' : [Bbox1, Bbox2 ... Bboxn],\n",
    "                                                              .\n",
    "                                                              .\n",
    "                                                              .\n",
    "                                                              'Phrase_id_n' : [Bbox1, Bbox2 ... Bboxn]}\n",
    "                                                              \n",
    "                                                              }\n",
    "                                                              \n",
    "                                                              \n",
    "        _Image_Train_Phrase_Id_to_Phrase -----> {'image_id_1' : {'Phrase_id_1' : [Phrase1, Phrase2.... Phrase_n],\n",
    "                                                              'Phrase_id_2' : [Phrase1, Phrase2.... Phrase_n],\n",
    "                                                              'Phrase_id_3' : [Phrase1, Phrase2.... Phrase_n],\n",
    "                                                              .\n",
    "                                                              .\n",
    "                                                              .\n",
    "                                                              'Phrase_id_n' : [Phrase1, Phrase2.... Phrase_n]}\n",
    "                                                              \n",
    "                                                'image_id_2' : {'Phrase_id_1' : [Phrase1, Phrase2.... Phrase_n],\n",
    "                                                              'Phrase_id_2' : [Phrase1, Phrase2.... Phrase_n],\n",
    "                                                              'Phrase_id_3' : [Phrase1, Phrase2.... Phrase_n],\n",
    "                                                              .\n",
    "                                                              .\n",
    "                                                              .\n",
    "                                                              'Phrase_id_n' : [Phrase1, Phrase2.... Phrase_n]}\n",
    "                                                              \n",
    "                                                              \n",
    "                                                              \n",
    "                                                              .\n",
    "                                                              .\n",
    "                                                              .\n",
    "                                                              .\n",
    "                                                              .\n",
    "                                                              .\n",
    "                                                              \n",
    "                                                              \n",
    "                                                'image_id_n' : {'Phrase_id_1' : [Phrase1, Phrase2.... Phrase_n],\n",
    "                                                              'Phrase_id_2' : [Phrase1, Phrase2.... Phrase_n],\n",
    "                                                              'Phrase_id_3' : [Phrase1, Phrase2.... Phrase_n],\n",
    "                                                              .\n",
    "                                                              .\n",
    "                                                              .\n",
    "                                                              'Phrase_id_n' : [Phrase1, Phrase2.... Phrase_n]}\n",
    "                                                              \n",
    "                                                              }\n",
    "        \n",
    "\n",
    "NOTE: Please alter any folder paths for Images, Sentences and Annotations (Phrase & Bounding Boxes) in Helper Function File\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "from collections import defaultdict\n",
    "def Mapping(_Image_Names, _paths_dict):\n",
    "    _Phrase_Id_to_Bbox = defaultdict()\n",
    "    _Phrase_Id_to_Phrase = defaultdict()\n",
    "\n",
    "    for _img in tqdm(_Image_Names):\n",
    "        _img_sentences_path, _img_annotations_path, _img_absolute_path = get_Paths(_img, _paths_dict)\n",
    "        sents = get_sentence_data(_img_sentences_path)\n",
    "        anns = get_annotations(_img_annotations_path)\n",
    "        _Phrase_Id_to_Bbox[_img] = phrase_Id_to_Bbox(sents, anns)\n",
    "        _Phrase_Id_to_Phrase[_img] = phrase_Id_to_Phrases(sents, anns)\n",
    "        \n",
    "        \n",
    "    return _Phrase_Id_to_Bbox, _Phrase_Id_to_Phrase\n",
    "\n",
    "\n",
    "_paths_dict = {\n",
    "                '_sentences_path' : r'/kaggle/input/vgrutils/Visual Grounding RefEx/Flickr30/Data/annotations/Sentences',\n",
    "                '_annotations_path' : r'/kaggle/input/vgrutils/Visual Grounding RefEx/Flickr30/Data/annotations/Annotations',\n",
    "                '_image_folder_path' : r'/kaggle/input/flickr30k/flickr30k_images'\n",
    "                }\n",
    "_train_len = 1000 #len(_trainimg)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "######################################################################################################################\n",
    "#                                                                                                                    #\n",
    "#                       Enter path for train, val & test split in their respective variables                         #\n",
    "#                                                                                                                    #\n",
    "######################################################################################################################\n",
    "\n",
    "\n",
    "train.txt, val.txt and test.txt are text files that contains predefined splits, i.e each file contains the split it\n",
    "belongs to.\n",
    "\n",
    "train.txt contains all image names as strings, that should be used for training\n",
    "val.txt contains all image names as strings, that should be used for validation\n",
    "test.txt contains all image names as strings, that should be used for testing\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "_trainimg = load_Splits('/kaggle/input/vgrutils/Visual Grounding RefEx/Flickr30/Data/Splits/train.txt')\n",
    "_vlimg = load_Splits('/kaggle/input/vgrutils/Visual Grounding RefEx/Flickr30/Data/Splits/val.txt')\n",
    "_tsimg = load_Splits('/kaggle/input/vgrutils/Visual Grounding RefEx/Flickr30/Data/Splits/test.txt')\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "######################################################################################################################\n",
    "#                                                                                                                    #\n",
    "#                                                 Call to the Mapping Functions                                      #\n",
    "#                                                                                                                    #\n",
    "######################################################################################################################\n",
    "\"\"\"\n",
    "\n",
    "_fractional_trainimg = _trainimg[:_train_len]\n",
    "_Image_Train_Phrase_Id_to_Bbox, _Image_Train_Phrase_Id_to_Phrase = Mapping(_fractional_trainimg, _paths_dict)\n",
    "_Image_Val_Phrase_Id_to_Bbox, _Image_Val_Phrase_Id_to_Phrase = Mapping(_vlimg, _paths_dict)\n",
    "_Image_Test_Phrase_Id_to_Bbox, _Image_Test_Phrase_Id_to_Phrase = Mapping(_tsimg, _paths_dict)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "######################################################################################################################\n",
    "#                                                                                                                    #\n",
    "#                                                 Part of Helper Functions.                                          #\n",
    "#                                                Needs to be updated there.                                          #\n",
    "#                                                                                                                    #\n",
    "######################################################################################################################\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "def prepare_DataFrame(Phrase_Dict, Bbox_Dict):\n",
    "    Final_DF = pd.DataFrame()\n",
    "    for Image_Id in tqdm(Phrase_Dict.keys()):\n",
    "        \n",
    "        Phrase_DF = pd.DataFrame.from_dict(Phrase_Dict[Image_Id], orient = 'index')\n",
    "        Phrase_DF = pd.DataFrame(Phrase_DF.stack(level=0)).reset_index().drop('level_1', axis = 1)\n",
    "\n",
    "        Bbox_DF = pd.DataFrame.from_dict(Bbox_Dict[Image_Id], orient = 'index')\n",
    "        Bbox_DF = pd.DataFrame(Bbox_DF.stack(level=0)).reset_index().drop('level_1', axis = 1)\n",
    "        Bbox_DF = Bbox_DF.groupby(['level_0'])[0].apply(list)\n",
    "        \n",
    "\n",
    "        Merged_DF = pd.merge(Phrase_DF, Bbox_DF, on = 'level_0', how='inner')\n",
    "        Merged_DF['Image_Id'] = Image_Id\n",
    "\n",
    "        Final_DF = pd.concat([Final_DF, Merged_DF], axis = 0)\n",
    "\n",
    "    Final_DF = Final_DF.rename(columns = {'level_0' : 'Phrase_Id', '0_x': 'Phrase', '0_y':'Bounding_Box'})\n",
    "    Final_DF = Final_DF[['Image_Id', 'Phrase_Id', 'Phrase', 'Bounding_Box']]\n",
    "    Final_DF.reset_index(drop = True, inplace = True)\n",
    "    print(\"Local Function Called......\")\n",
    "    return Final_DF\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "######################################################################################################################\n",
    "#                                                                                                                    #\n",
    "#                                                Converting to DataFrames.                                           #\n",
    "#                                                                                                                    #\n",
    "######################################################################################################################\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "Train_Frame = prepare_DataFrame(_Image_Train_Phrase_Id_to_Phrase, _Image_Train_Phrase_Id_to_Bbox)\n",
    "Val_Frame = prepare_DataFrame(_Image_Val_Phrase_Id_to_Phrase, _Image_Val_Phrase_Id_to_Bbox)\n",
    "Test_Frame = prepare_DataFrame(_Image_Test_Phrase_Id_to_Phrase, _Image_Test_Phrase_Id_to_Bbox)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "######################################################################################################################\n",
    "#                                                                                                                    #\n",
    "#                                    Lower Case Phrases & Phrase to Index Map                                        #\n",
    "#                                                                                                                    #\n",
    "######################################################################################################################\n",
    "\"\"\"\n",
    "\n",
    "def sort_by_number_of_words(phrase):\n",
    "    return len(phrase.split())\n",
    "\n",
    "Train_Frame.Phrase = Train_Frame.Phrase.str.lower()\n",
    "Val_Frame.Phrase = Val_Frame.Phrase.str.lower()\n",
    "Test_Frame.Phrase = Test_Frame.Phrase.str.lower()\n",
    "\n",
    "\n",
    "unique_Phrases_Train = list(Train_Frame.Phrase.unique())\n",
    "unique_Phrases_Train.sort(key = sort_by_number_of_words)\n",
    "_train_Phrase_to_Index_Map = dict(zip(unique_Phrases_Train, range(len(unique_Phrases_Train))))\n",
    "\n",
    "unique_Phrases_Val = list(Val_Frame.Phrase.unique())\n",
    "unique_Phrases_Val.sort(key = sort_by_number_of_words)\n",
    "_val_Phrase_to_Index_Map = dict(zip(unique_Phrases_Val, range(len(unique_Phrases_Val))))\n",
    "\n",
    "unique_Phrases_Test = list(Test_Frame.Phrase.unique())\n",
    "unique_Phrases_Test.sort(key = sort_by_number_of_words)\n",
    "_test_Phrase_to_Index_Map = dict(zip(unique_Phrases_Test, range(len(unique_Phrases_Test))))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-25T21:21:49.545127Z",
     "iopub.status.busy": "2023-04-25T21:21:49.544586Z",
     "iopub.status.idle": "2023-04-25T21:21:49.584682Z",
     "shell.execute_reply": "2023-04-25T21:21:49.583220Z",
     "shell.execute_reply.started": "2023-04-25T21:21:49.545074Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image_Id</th>\n",
       "      <th>Phrase_Id</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Bounding_Box</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3359636318</td>\n",
       "      <td>112630</td>\n",
       "      <td>two people</td>\n",
       "      <td>[[46, 182, 105, 333], [143, 165, 207, 333]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3359636318</td>\n",
       "      <td>112632</td>\n",
       "      <td>the video game shop</td>\n",
       "      <td>[[0, 54, 168, 307]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3359636318</td>\n",
       "      <td>112631</td>\n",
       "      <td>the mobile phone store</td>\n",
       "      <td>[[191, 0, 498, 230]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3359636318</td>\n",
       "      <td>112625</td>\n",
       "      <td>several people</td>\n",
       "      <td>[[46, 182, 105, 333], [143, 165, 207, 333], [2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3359636318</td>\n",
       "      <td>112625</td>\n",
       "      <td>people</td>\n",
       "      <td>[[46, 182, 105, 333], [143, 165, 207, 333], [2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3359636318</td>\n",
       "      <td>112625</td>\n",
       "      <td>a group of people</td>\n",
       "      <td>[[46, 182, 105, 333], [143, 165, 207, 333], [2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3359636318</td>\n",
       "      <td>112627</td>\n",
       "      <td>some stores</td>\n",
       "      <td>[[191, 0, 498, 230], [1, 0, 190, 307]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3359636318</td>\n",
       "      <td>112626</td>\n",
       "      <td>a sidewalk</td>\n",
       "      <td>[[2, 212, 499, 333]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6959556104</td>\n",
       "      <td>262504</td>\n",
       "      <td>the crowd</td>\n",
       "      <td>[[5, 70, 103, 314], [120, 54, 206, 172], [197,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6959556104</td>\n",
       "      <td>262504</td>\n",
       "      <td>a small crowd</td>\n",
       "      <td>[[5, 70, 103, 314], [120, 54, 206, 172], [197,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Image_Id Phrase_Id                  Phrase  \\\n",
       "0  3359636318    112630              two people   \n",
       "1  3359636318    112632     the video game shop   \n",
       "2  3359636318    112631  the mobile phone store   \n",
       "3  3359636318    112625          several people   \n",
       "4  3359636318    112625                  people   \n",
       "5  3359636318    112625       a group of people   \n",
       "6  3359636318    112627             some stores   \n",
       "7  3359636318    112626              a sidewalk   \n",
       "8  6959556104    262504               the crowd   \n",
       "9  6959556104    262504           a small crowd   \n",
       "\n",
       "                                        Bounding_Box  \n",
       "0        [[46, 182, 105, 333], [143, 165, 207, 333]]  \n",
       "1                                [[0, 54, 168, 307]]  \n",
       "2                               [[191, 0, 498, 230]]  \n",
       "3  [[46, 182, 105, 333], [143, 165, 207, 333], [2...  \n",
       "4  [[46, 182, 105, 333], [143, 165, 207, 333], [2...  \n",
       "5  [[46, 182, 105, 333], [143, 165, 207, 333], [2...  \n",
       "6             [[191, 0, 498, 230], [1, 0, 190, 307]]  \n",
       "7                               [[2, 212, 499, 333]]  \n",
       "8  [[5, 70, 103, 314], [120, 54, 206, 172], [197,...  \n",
       "9  [[5, 70, 103, 314], [120, 54, 206, 172], [197,...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "######################################################################################################################\n",
    "#                                                                                                                    #\n",
    "#                                                Printing the DataFrames.                                            #\n",
    "#                                                                                                                    #\n",
    "######################################################################################################################\n",
    "\"\"\"\n",
    "\n",
    "Train_Frame.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-25T21:21:49.586411Z",
     "iopub.status.busy": "2023-04-25T21:21:49.586067Z",
     "iopub.status.idle": "2023-04-25T21:21:49.618847Z",
     "shell.execute_reply": "2023-04-25T21:21:49.617349Z",
     "shell.execute_reply.started": "2023-04-25T21:21:49.586379Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image_Id</th>\n",
       "      <th>Phrase_Id</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Bounding_Box</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1016887272</td>\n",
       "      <td>547</td>\n",
       "      <td>a collage of one person</td>\n",
       "      <td>[[193, 369, 230, 453], [207, 303, 255, 383], [...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1016887272</td>\n",
       "      <td>547</td>\n",
       "      <td>a group of people</td>\n",
       "      <td>[[193, 369, 230, 453], [207, 303, 255, 383], [...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1016887272</td>\n",
       "      <td>547</td>\n",
       "      <td>several climbers</td>\n",
       "      <td>[[193, 369, 230, 453], [207, 303, 255, 383], [...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1016887272</td>\n",
       "      <td>547</td>\n",
       "      <td>seven climbers</td>\n",
       "      <td>[[193, 369, 230, 453], [207, 303, 255, 383], [...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1016887272</td>\n",
       "      <td>548</td>\n",
       "      <td>the rock</td>\n",
       "      <td>[[0, 53, 332, 499]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1016887272</td>\n",
       "      <td>548</td>\n",
       "      <td>a rock climbing wall</td>\n",
       "      <td>[[0, 53, 332, 499]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1016887272</td>\n",
       "      <td>548</td>\n",
       "      <td>a rock face</td>\n",
       "      <td>[[0, 53, 332, 499]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1016887272</td>\n",
       "      <td>548</td>\n",
       "      <td>a rock</td>\n",
       "      <td>[[0, 53, 332, 499]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1016887272</td>\n",
       "      <td>548</td>\n",
       "      <td>a cliff</td>\n",
       "      <td>[[0, 53, 332, 499]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1016887272</td>\n",
       "      <td>549</td>\n",
       "      <td>another man</td>\n",
       "      <td>[[73, 301, 180, 499]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Image_Id Phrase_Id                   Phrase  \\\n",
       "0  1016887272       547  a collage of one person   \n",
       "1  1016887272       547        a group of people   \n",
       "2  1016887272       547         several climbers   \n",
       "3  1016887272       547           seven climbers   \n",
       "4  1016887272       548                 the rock   \n",
       "5  1016887272       548     a rock climbing wall   \n",
       "6  1016887272       548              a rock face   \n",
       "7  1016887272       548                   a rock   \n",
       "8  1016887272       548                  a cliff   \n",
       "9  1016887272       549              another man   \n",
       "\n",
       "                                        Bounding_Box  \n",
       "0  [[193, 369, 230, 453], [207, 303, 255, 383], [...  \n",
       "1  [[193, 369, 230, 453], [207, 303, 255, 383], [...  \n",
       "2  [[193, 369, 230, 453], [207, 303, 255, 383], [...  \n",
       "3  [[193, 369, 230, 453], [207, 303, 255, 383], [...  \n",
       "4                                [[0, 53, 332, 499]]  \n",
       "5                                [[0, 53, 332, 499]]  \n",
       "6                                [[0, 53, 332, 499]]  \n",
       "7                                [[0, 53, 332, 499]]  \n",
       "8                                [[0, 53, 332, 499]]  \n",
       "9                              [[73, 301, 180, 499]]  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "######################################################################################################################\n",
    "#                                                                                                                    #\n",
    "#                                                Printing the DataFrames.                                            #\n",
    "#                                                                                                                    #\n",
    "######################################################################################################################\n",
    "\"\"\"\n",
    "\n",
    "Test_Frame.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-25T21:21:49.621335Z",
     "iopub.status.busy": "2023-04-25T21:21:49.620837Z",
     "iopub.status.idle": "2023-04-25T21:21:49.644455Z",
     "shell.execute_reply": "2023-04-25T21:21:49.642507Z",
     "shell.execute_reply.started": "2023-04-25T21:21:49.621279Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image_Id</th>\n",
       "      <th>Phrase_Id</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Bounding_Box</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100652400</td>\n",
       "      <td>197</td>\n",
       "      <td>a construction worker</td>\n",
       "      <td>[[52, 44, 109, 202]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100652400</td>\n",
       "      <td>197</td>\n",
       "      <td>a man</td>\n",
       "      <td>[[52, 44, 109, 202]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100652400</td>\n",
       "      <td>198</td>\n",
       "      <td>hard hat</td>\n",
       "      <td>[[58, 43, 87, 65]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100652400</td>\n",
       "      <td>198</td>\n",
       "      <td>a blue hard hat</td>\n",
       "      <td>[[58, 43, 87, 65]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100652400</td>\n",
       "      <td>198</td>\n",
       "      <td>a hard hat</td>\n",
       "      <td>[[58, 43, 87, 65]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100652400</td>\n",
       "      <td>199</td>\n",
       "      <td>a reflective vest</td>\n",
       "      <td>[[61, 68, 97, 118]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100652400</td>\n",
       "      <td>199</td>\n",
       "      <td>a caution vest</td>\n",
       "      <td>[[61, 68, 97, 118]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>100652400</td>\n",
       "      <td>199</td>\n",
       "      <td>orange safety vest</td>\n",
       "      <td>[[61, 68, 97, 118]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>100652400</td>\n",
       "      <td>199</td>\n",
       "      <td>bright vest</td>\n",
       "      <td>[[61, 68, 97, 118]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>100652400</td>\n",
       "      <td>200</td>\n",
       "      <td>an intersection</td>\n",
       "      <td>[[0, 89, 373, 499]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Image_Id Phrase_Id                 Phrase          Bounding_Box\n",
       "0  100652400       197  a construction worker  [[52, 44, 109, 202]]\n",
       "1  100652400       197                  a man  [[52, 44, 109, 202]]\n",
       "2  100652400       198               hard hat    [[58, 43, 87, 65]]\n",
       "3  100652400       198        a blue hard hat    [[58, 43, 87, 65]]\n",
       "4  100652400       198             a hard hat    [[58, 43, 87, 65]]\n",
       "5  100652400       199      a reflective vest   [[61, 68, 97, 118]]\n",
       "6  100652400       199         a caution vest   [[61, 68, 97, 118]]\n",
       "7  100652400       199     orange safety vest   [[61, 68, 97, 118]]\n",
       "8  100652400       199            bright vest   [[61, 68, 97, 118]]\n",
       "9  100652400       200        an intersection   [[0, 89, 373, 499]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "######################################################################################################################\n",
    "#                                                                                                                    #\n",
    "#                                                Printing the DataFrames.                                            #\n",
    "#                                                                                                                    #\n",
    "######################################################################################################################\n",
    "\"\"\"\n",
    "\n",
    "Val_Frame.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-25T21:21:49.648102Z",
     "iopub.status.busy": "2023-04-25T21:21:49.647636Z",
     "iopub.status.idle": "2023-04-25T21:22:02.846004Z",
     "shell.execute_reply": "2023-04-25T21:22:02.844541Z",
     "shell.execute_reply.started": "2023-04-25T21:21:49.648058Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytorch-pretrained-bert in /opt/conda/lib/python3.7/site-packages (0.6.2)\n",
      "Requirement already satisfied: regex in /opt/conda/lib/python3.7/site-packages (from pytorch-pretrained-bert) (2021.11.10)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from pytorch-pretrained-bert) (2.28.2)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from pytorch-pretrained-bert) (1.21.6)\n",
      "Requirement already satisfied: torch>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from pytorch-pretrained-bert) (1.13.0+cpu)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from pytorch-pretrained-bert) (4.64.1)\n",
      "Requirement already satisfied: boto3 in /opt/conda/lib/python3.7/site-packages (from pytorch-pretrained-bert) (1.26.100)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch>=0.4.1->pytorch-pretrained-bert) (4.4.0)\n",
      "Requirement already satisfied: botocore<1.30.0,>=1.29.100 in /opt/conda/lib/python3.7/site-packages (from boto3->pytorch-pretrained-bert) (1.29.120)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.7/site-packages (from boto3->pytorch-pretrained-bert) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from boto3->pytorch-pretrained-bert) (0.6.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->pytorch-pretrained-bert) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->pytorch-pretrained-bert) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->pytorch-pretrained-bert) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->pytorch-pretrained-bert) (1.26.14)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.7/site-packages (from botocore<1.30.0,>=1.29.100->boto3->pytorch-pretrained-bert) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.30.0,>=1.29.100->boto3->pytorch-pretrained-bert) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install pytorch-pretrained-bert\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-25T21:23:09.642974Z",
     "iopub.status.busy": "2023-04-25T21:23:09.642540Z",
     "iopub.status.idle": "2023-04-25T21:24:33.954099Z",
     "shell.execute_reply": "2023-04-25T21:24:33.952713Z",
     "shell.execute_reply.started": "2023-04-25T21:23:09.642933Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 2471, 2045, 102]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32e66a0ff92e4e53b6b4e3a1fcbff2bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/93 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "class Bert(nn.Module):\n",
    "    \n",
    "    #Constructor\n",
    "    def __init__(self):\n",
    "        super(Bert, self).__init__()\n",
    "        \n",
    "        #Load the Pretrained Model\n",
    "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "        self.model = BertModel.from_pretrained('bert-base-uncased')\n",
    "        \n",
    "        #Hook Features\n",
    "        self.Features = {}\n",
    "        self.hook = self.model.encoder.layer[-2].register_forward_hook(self.get_features('second_last_hidden_state'))\n",
    "      \n",
    "    #Hook Registration\n",
    "    def get_features(self, name):\n",
    "        def hook(model, input, output):\n",
    "#             print(\"hook invoked\")\n",
    "            processed = torch.mean(output,dim = 1)\n",
    "            self.Features[name] = processed.detach()\n",
    "        return hook\n",
    "    \n",
    "    \n",
    "    \n",
    "    def preprocess_Phrases(self, phrase):\n",
    "        marked_phrase = \"[CLS] \" + phrase + \" [SEP]\"\n",
    "        tokenized_phrase = self.tokenizer.tokenize(marked_phrase)\n",
    "        tokenized_index = self.tokenizer.convert_tokens_to_ids(tokenized_phrase)\n",
    "        return tokenized_index\n",
    "\n",
    "\n",
    "    def preprocess_Batch(self, batch, padding_id):\n",
    "\n",
    "        token_Ids = list(map(self.preprocess_Phrases, batch))\n",
    "        max_len = len(max(token_Ids, key = len))\n",
    "\n",
    "\n",
    "        for index, tkn_ind in enumerate(token_Ids):\n",
    "            pad_len = max_len - len(tkn_ind)\n",
    "            pad_seq = [padding_id] * pad_len\n",
    "            token_Ids[index] += pad_seq\n",
    "\n",
    "        token_Ids_Tensor = torch.tensor(token_Ids)\n",
    "        segment_Ids_Tensor = torch.ones(token_Ids_Tensor.shape, dtype= torch.long)\n",
    "        return token_Ids_Tensor, segment_Ids_Tensor\n",
    "    \n",
    "    \n",
    "    def forward(self, batches, _phrase = None, training = True):\n",
    "        Textual_Embeddings = None\n",
    "        if training:\n",
    "            Textual_Embeddings = []\n",
    "            pad = self.tokenizer.vocab['pad']\n",
    "            for batch in tqdm(batches):\n",
    "                tk, sg = self.preprocess_Batch(batch, pad)\n",
    "                _, _ = self.model(tk, sg)\n",
    "                Textual_Embeddings.append(self.Features['second_last_hidden_state'])\n",
    "            Textual_Embeddings = torch.vstack(Textual_Embeddings)\n",
    "            \n",
    "        else:\n",
    "            tk_ids = self.preprocess_Phrases(_phrase)\n",
    "            print(tk_ids)\n",
    "            tk = torch.tensor(tk_ids).reshape(1,-1)\n",
    "            sg = torch.ones(tk.shape, dtype = torch.long).reshape(1,-1)\n",
    "            _, _ = self.model(tk, sg)\n",
    "            Textual_Embeddings = self.Features['second_last_hidden_state']\n",
    "            \n",
    "\n",
    "        return Textual_Embeddings\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "batch_size = 64\n",
    "train_batches = [unique_Phrases_Train[i:i+batch_size] for i in range(0,len(unique_Phrases_Train),batch_size)]\n",
    "val_batches = [unique_Phrases_Val[i:i+batch_size] for i in range(0,len(unique_Phrases_Val),batch_size)]\n",
    "test_batches = [unique_Phrases_Test[i:i+batch_size] for i in range(0,len(unique_Phrases_Test),batch_size)]\n",
    " \n",
    "    \n",
    "    \n",
    "Obj = Bert()\n",
    "emb = Obj.forward(None, _phrase = \"Almost There\", training=False)\n",
    "t_train_embeds = Obj.forward(train_batches)\n",
    "torch.save(t_train_embeds,\"/kaggle/working/t_train_embeds.pt\")\n",
    "\n",
    "with open('/kaggle/working/_train_Phrase_to_Index_Map.pkl', 'wb') as fp:\n",
    "    pickle.dump(_train_Phrase_to_Index_Map, fp)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
