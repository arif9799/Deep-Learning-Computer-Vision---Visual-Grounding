{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prior Code (Data Fetch and Prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-24T19:03:29.286236Z",
     "iopub.status.busy": "2023-04-24T19:03:29.285285Z",
     "iopub.status.idle": "2023-04-24T19:03:39.879943Z",
     "shell.execute_reply": "2023-04-24T19:03:39.878723Z",
     "shell.execute_reply.started": "2023-04-24T19:03:29.286194Z"
    }
   },
   "outputs": [],
   "source": [
    "######################################################################################################################\n",
    "#                               Import Python Files for Sentence & Annotations Extraction                            #\n",
    "#                                        Provided as a Simple API on Github                                          #\n",
    "#                                https://github.com/BryanPlummer/flickr30k_entities                                  #\n",
    "######################################################################################################################\n",
    "\n",
    "\n",
    "# Uncomment the below line once in order for the code to run smoothly\n",
    "!pip install imagesize\n",
    "\n",
    "import os\n",
    "os.chdir(r\"/kaggle/input/vgrutils/Visual Grounding RefEx/Flickr30/\")\n",
    "\n",
    "import Utils.flickr30k_entities_utils\n",
    "from Utils.flickr30k_entities_utils import get_sentence_data, get_annotations\n",
    "\n",
    "import Utils.helper_functions\n",
    "from Utils.helper_functions import *\n",
    "\n",
    "import random \n",
    "import seaborn as sb\n",
    "\n",
    "\n",
    "\n",
    "######################################################################################################################\n",
    "#                                                                                                                    #\n",
    "#                                                   Mapping Function                                                 #\n",
    "#                                                                                                                    #\n",
    "######################################################################################################################\n",
    "\"\"\"\n",
    "Mapping Function does the following,\n",
    "    - takes list of Image names as i/p and fetch Sentences & Annotations (contains bounding boxes)of all those Images\n",
    "    - passes those Sentences & Annotations to the func Phrase_Id_to_Bbox & gets Bounding Boxes for all phrases\n",
    "    in every image.\n",
    "    - also, passes those Sentences & Annotations to the func Phrase_Id_to_Phrases & extracts phrases contained in all\n",
    "    images.\n",
    "    \n",
    "    A typical look of the outputs would be:\n",
    "    \n",
    "        _Image_Train_Phrase_Id_to_Bbox -----> {'image_id_1' : {'Phrase_id_1' : [Bbox1, Bbox2 ... Bboxn],\n",
    "                                                              'Phrase_id_2' : [Bbox1, Bbox2 ... Bboxn],\n",
    "                                                              'Phrase_id_3' : [Bbox1, Bbox2 ... Bboxn],\n",
    "                                                              .\n",
    "                                                              .\n",
    "                                                              .\n",
    "                                                              'Phrase_id_n' : [Bbox1, Bbox2 ... Bboxn]}\n",
    "                                                              \n",
    "                                                'image_id_2' : {'Phrase_id_1' : [Bbox1, Bbox2 ... Bboxn],\n",
    "                                                              'Phrase_id_2' : [Bbox1, Bbox2 ... Bboxn],\n",
    "                                                              'Phrase_id_3' : [Bbox1, Bbox2 ... Bboxn],\n",
    "                                                              .\n",
    "                                                              .\n",
    "                                                              .\n",
    "                                                              'Phrase_id_n' : [Bbox1, Bbox2 ... Bboxn]}\n",
    "                                                              \n",
    "                                                              \n",
    "                                                              \n",
    "                                                              .\n",
    "                                                              .\n",
    "                                                              .\n",
    "                                                              .\n",
    "                                                              .\n",
    "                                                              .\n",
    "                                                              \n",
    "                                                              \n",
    "                                                'image_id_n' : {'Phrase_id_1' : [Bbox1, Bbox2 ... Bboxn],\n",
    "                                                              'Phrase_id_2' : [Bbox1, Bbox2 ... Bboxn],\n",
    "                                                              'Phrase_id_3' : [Bbox1, Bbox2 ... Bboxn],\n",
    "                                                              .\n",
    "                                                              .\n",
    "                                                              .\n",
    "                                                              'Phrase_id_n' : [Bbox1, Bbox2 ... Bboxn]}\n",
    "                                                              \n",
    "                                                              }\n",
    "                                                              \n",
    "                                                              \n",
    "        _Image_Train_Phrase_Id_to_Phrase -----> {'image_id_1' : {'Phrase_id_1' : [Phrase1, Phrase2.... Phrase_n],\n",
    "                                                              'Phrase_id_2' : [Phrase1, Phrase2.... Phrase_n],\n",
    "                                                              'Phrase_id_3' : [Phrase1, Phrase2.... Phrase_n],\n",
    "                                                              .\n",
    "                                                              .\n",
    "                                                              .\n",
    "                                                              'Phrase_id_n' : [Phrase1, Phrase2.... Phrase_n]}\n",
    "                                                              \n",
    "                                                'image_id_2' : {'Phrase_id_1' : [Phrase1, Phrase2.... Phrase_n],\n",
    "                                                              'Phrase_id_2' : [Phrase1, Phrase2.... Phrase_n],\n",
    "                                                              'Phrase_id_3' : [Phrase1, Phrase2.... Phrase_n],\n",
    "                                                              .\n",
    "                                                              .\n",
    "                                                              .\n",
    "                                                              'Phrase_id_n' : [Phrase1, Phrase2.... Phrase_n]}\n",
    "                                                              \n",
    "                                                              \n",
    "                                                              \n",
    "                                                              .\n",
    "                                                              .\n",
    "                                                              .\n",
    "                                                              .\n",
    "                                                              .\n",
    "                                                              .\n",
    "                                                              \n",
    "                                                              \n",
    "                                                'image_id_n' : {'Phrase_id_1' : [Phrase1, Phrase2.... Phrase_n],\n",
    "                                                              'Phrase_id_2' : [Phrase1, Phrase2.... Phrase_n],\n",
    "                                                              'Phrase_id_3' : [Phrase1, Phrase2.... Phrase_n],\n",
    "                                                              .\n",
    "                                                              .\n",
    "                                                              .\n",
    "                                                              'Phrase_id_n' : [Phrase1, Phrase2.... Phrase_n]}\n",
    "                                                              \n",
    "                                                              }\n",
    "        \n",
    "\n",
    "NOTE: Please alter any folder paths for Images, Sentences and Annotations (Phrase & Bounding Boxes) in Helper Function File\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "from collections import defaultdict\n",
    "def Mapping(_Image_Names, _paths_dict):\n",
    "    _Phrase_Id_to_Bbox = defaultdict()\n",
    "    _Phrase_Id_to_Phrase = defaultdict()\n",
    "\n",
    "    for _img in tqdm(_Image_Names):\n",
    "        _img_sentences_path, _img_annotations_path, _img_absolute_path = get_Paths(_img, _paths_dict)\n",
    "        sents = get_sentence_data(_img_sentences_path)\n",
    "        anns = get_annotations(_img_annotations_path)\n",
    "        _Phrase_Id_to_Bbox[_img] = phrase_Id_to_Bbox(sents, anns)\n",
    "        _Phrase_Id_to_Phrase[_img] = phrase_Id_to_Phrases(sents, anns)\n",
    "        \n",
    "    \n",
    "    return _Phrase_Id_to_Bbox, _Phrase_Id_to_Phrase\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "######################################################################################################################\n",
    "#                                                                                                                    #\n",
    "#                                                 All Important Paths                                                #\n",
    "#                                                                                                                    #\n",
    "######################################################################################################################\n",
    "_paths_dict = {\n",
    "                '_sentences_path' : r'/kaggle/input/vgrutils/Visual Grounding RefEx/Flickr30/Data/annotations/Sentences',\n",
    "                '_annotations_path' : r'/kaggle/input/vgrutils/Visual Grounding RefEx/Flickr30/Data/annotations/Annotations',\n",
    "                '_image_folder_path' : r'/kaggle/input/flickr30k/flickr30k_images'\n",
    "                }\n",
    "_train_len = 1000 #len(_trainimg)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "######################################################################################################################\n",
    "#                                                                                                                    #\n",
    "#                       Enter path for train, val & test split in their respective variables                         #\n",
    "#                                                                                                                    #\n",
    "######################################################################################################################\n",
    "\"\"\"\n",
    "train.txt, val.txt and test.txt are text files that contains predefined splits, i.e each file contains the split it\n",
    "belongs to.\n",
    "\n",
    "train.txt contains all image names as strings, that should be used for training\n",
    "val.txt contains all image names as strings, that should be used for validation\n",
    "test.txt contains all image names as strings, that should be used for testing\n",
    "\"\"\"\n",
    "\n",
    "_trainimg = load_Splits('/kaggle/input/vgrutils/Visual Grounding RefEx/Flickr30/Data/Splits/train.txt')\n",
    "_vlimg = load_Splits('/kaggle/input/vgrutils/Visual Grounding RefEx/Flickr30/Data/Splits/val.txt')\n",
    "_tsimg = load_Splits('/kaggle/input/vgrutils/Visual Grounding RefEx/Flickr30/Data/Splits/test.txt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VISION TRANSFORMER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.models import vit_b_16 as vit_model\n",
    "from torchvision.models import ViT_B_16_Weights as vit_model_weights\n",
    "from tqdm.notebook import tqdm\n",
    "import PIL \n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-24T19:06:53.158748Z",
     "iopub.status.busy": "2023-04-24T19:06:53.157934Z",
     "iopub.status.idle": "2023-04-24T19:06:54.578723Z",
     "shell.execute_reply": "2023-04-24T19:06:54.577613Z",
     "shell.execute_reply.started": "2023-04-24T19:06:53.158705Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "class ViT(nn.Module):\n",
    "    \n",
    "    #Constructor\n",
    "    def __init__(self):\n",
    "        super(ViT, self).__init__()\n",
    "        \n",
    "        #Load the Pretrained Model\n",
    "        self.ViT_Weights = vit_model_weights(vit_model_weights.DEFAULT)\n",
    "        self.ViT_Transforms = self.ViT_Weights.transforms()\n",
    "        self.model = vit_model(weights=self.ViT_Weights)\n",
    "        \n",
    "        #Does not require training, so set the Gradients to False\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = False\n",
    "            \n",
    "        #Hook Variables\n",
    "        self.Features = {}\n",
    "        self.hook = self.model.encoder.ln.register_forward_hook(self.get_features('last_hidden_state'))\n",
    "\n",
    "    #Hook Registration\n",
    "    def get_features(self, name):\n",
    "        def hook(model, input, output):\n",
    "            self.Features[name] = output[:,0,:].detach()\n",
    "        return hook\n",
    "    \n",
    "    def forward(self, batches, paths_dict, _image=None, training = True):\n",
    "        if training:\n",
    "            Vision_Embeddings = []\n",
    "            Image_Ids = []\n",
    "            for batch in tqdm(batches):\n",
    "                image_batch = []\n",
    "                for image in batch:\n",
    "                    Image_Ids.append(image)\n",
    "                    _,_,img_path = get_Paths(image_name= image, _paths= paths_dict)\n",
    "                    image_loaded = Image.open(img_path)\n",
    "                    image_transformed = self.ViT_Transforms(image_loaded)\n",
    "                    image_batch.append(image_transformed)\n",
    "\n",
    "                transformed_image_batch = torch.stack(image_batch)\n",
    "                _ = self.model.forward(transformed_image_batch)\n",
    "                Vision_Embeddings.append(self.Features['last_hidden_state'])\n",
    "            Vision_Embeddings = torch.vstack(Vision_Embeddings)\n",
    "        else:\n",
    "            Vision_Embeddings = None\n",
    "            image_transformed = self.ViT_Transforms(_image)\n",
    "            image_transformed = image_transformed.unsqueeze(0)\n",
    "            _ = self.model(image_transformed)\n",
    "            Vision_Embeddings = self.Features['last_hidden_state']\n",
    "        \n",
    "        return Vision_Embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-24T19:07:06.348598Z",
     "iopub.status.busy": "2023-04-24T19:07:06.347822Z",
     "iopub.status.idle": "2023-04-24T19:07:06.772412Z",
     "shell.execute_reply": "2023-04-24T19:07:06.771247Z",
     "shell.execute_reply.started": "2023-04-24T19:07:06.348558Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "_trainimg_temp = _trainimg[:_train_len]\n",
    "batch_size = 32\n",
    "train_batches = [_trainimg[i:i+batch_size] for i in range(0,len(_trainimg_temp),batch_size)]\n",
    "val_batches = [_vlimg[i:i+batch_size] for i in range(0,len(_vlimg),batch_size)]\n",
    "test_batches = [_tsimg[i:i+batch_size] for i in range(0,len(_tsimg),batch_size)]\n",
    "del _trainimg_temp\n",
    "\n",
    "obj = ViT()\n",
    "_,_,img_path = get_Paths(image_name= train_batches[0][0], _paths= _paths_dict)\n",
    "one_instance = Image.open(img_path)\n",
    "emb = obj.forward(batches = None, paths_dict = None, _image = one_instance, training = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
